{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COGS 160 Auto-Grader Notebook for Architect Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain_setup_llama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import fitz  \n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from urllib.parse import urlparse\n",
    "import spacy\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=GEMINI_API_KEY) \n",
    "text_model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "vision_model = genai.GenerativeModel(\"gemini-pro-vision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rubric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric = {\n",
    "    \"architect_chosen\": 5,\n",
    "    \"bio_750_words\": 10,\n",
    "    \"bio_structure\": 10,\n",
    "    \"bio_references\": 10,\n",
    "    \"10_buildings_with_images\": 15,\n",
    "    \"image_quality\": 10,\n",
    "    \"image_citations\": 10,\n",
    "    \"personal_bio_photo\": 5,\n",
    "    \"doc_and_slides\": 5,\n",
    "    \"image_relevance\": 10,\n",
    "    \"presentation_polish\": 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Extract text from PDF\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"/Users/tanishqsingh/Desktop/XR_Lab/cogs160submisson1.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    print(f\"üîç Extracting text from: {pdf_path}\")\n",
    "    text = \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    print(\"‚úî Extracted text from PDF\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Extract images from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_pdf(pdf_path, min_width=1200, save_folder=\"/Users/tanishqsingh/Desktop/XR_Lab/Extracted_images\"):\n",
    "    print(f\" Extracting images from: {pdf_path}\")\n",
    "    doc = fitz.open(pdf_path)\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    image_data = []\n",
    "    for page_index in range(len(doc)):\n",
    "        images = doc.get_page_images(page_index)\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            img_pil = Image.open(BytesIO(image_bytes))\n",
    "            width, height = img_pil.size\n",
    "            img_pil.save(os.path.join(save_folder, f\"page{page_index+1}_img{img_index+1}.png\"))\n",
    "            image_data.append({\n",
    "                \"page\": page_index + 1,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"image\": img_pil,\n",
    "                \"is_high_res\": width >= min_width\n",
    "            })\n",
    "    print(f\" Extracted {len(image_data)} images from PDF\")\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate biography structure & word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_biography(text):\n",
    "    print(\" Evaluating biography: checking word count and required sections\")\n",
    "    result = {}\n",
    "    doc = nlp(text)\n",
    "    result[\"word_count\"] = len([token.text for token in doc if token.is_alpha])\n",
    "    required_sections = [\"who they are\", \"studied\", \"first building\", \"significance\", \"influence\"]\n",
    "    section_hits = sum([1 for section in required_sections if section.lower() in text.lower()])\n",
    "    result[\"structure_score\"] = int((section_hits / len(required_sections)) * rubric[\"bio_structure\"])\n",
    "    result[\"score\"] = rubric[\"bio_750_words\"] if result[\"word_count\"] >= 700 else int((result[\"word_count\"] / 750) * rubric[\"bio_750_words\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini Bio Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_bio_score(text, architect_name, debug=False):\n",
    "    print(f\" Sending biography text to Gemini for evaluation of {architect_name}\")\n",
    "    prompt = f\"\"\"\n",
    "You are grading a student's biography of the architect {architect_name}.\n",
    "Evaluate:\n",
    "- Who they are\n",
    "- What they‚Äôre famous for\n",
    "- Where they studied\n",
    "- Significance in architecture\n",
    "- Influence of buildings\n",
    "- Types of buildings\n",
    "- First building attributed\n",
    "Give a score out of 10 and 1-paragraph feedback.\n",
    "\"\"\"\n",
    "    response = text_model.generate_content([prompt, text])\n",
    "    if debug:\n",
    "        print(\" Gemini Bio Evaluation (Initial):\", response.text)\n",
    "        print(\" Asking Gemini to reconsider harshness in bio scoring...\")\n",
    "        retry_prompt = \"Was this scoring too harsh? Re-evaluate the student‚Äôs biography with more weight on effort and project instructions.\"\n",
    "        reconsidered = text_model.generate_content([retry_prompt, response.text])\n",
    "        print(\" Reconsidered Bio Evaluation:\", reconsidered.text)\n",
    "    if debug:\n",
    "        print(\"Full Gemini Rubric Feedback:\", response.text)\n",
    "        print(\" Asking Gemini to reconsider harshness...\")\n",
    "        retry_prompt = \"Was this scoring overly harsh? Re-evaluate with more weight on the student's effort and assignment instructions.\"\n",
    "        second_response = text_model.generate_content([retry_prompt, response.text])\n",
    "        print(\" Reconsidered Response:\", second_response.text)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract references from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_references_from_text(text):\n",
    "    print(\"üîç Extracting references from text\")\n",
    "    lines = text.split(\"\\n\")\n",
    "    references = []\n",
    "    for line in lines:\n",
    "        if re.search(r\"\\(\\d{4}\\)\", line) and any(x in line.lower() for x in [\"doi\", \"archdaily\", \"e-architect\", \"https://\"]):\n",
    "            references.append(line.strip())\n",
    "    return references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_references(ref_list):\n",
    "    print(\" Evaluating references\")\n",
    "    if not ref_list:\n",
    "        return {\"valid_references\": 0, \"score\": 0}\n",
    "\n",
    "    joined_refs = \"\\n\".join(ref_list)\n",
    "    prompt = f\"\"\"\n",
    "You are an academic writing assistant.\n",
    "Below is a list of references extracted from a student's architecture assignment:\n",
    "\n",
    "{joined_refs}\n",
    "\n",
    "Evaluate the overall quality of these references based on the following:\n",
    "- Are they properly formatted in APA style?\n",
    "- Are they from credible sources (e.g., books, peer-reviewed journals, respected architecture websites)?\n",
    "- Are there enough academic references (minimum of 5 is ideal)?\n",
    "\n",
    "Give a score out of 10 for reference quality, and provide a short justification.\n",
    "\"\"\"\n",
    "    response = text_model.generate_content([prompt])\n",
    "    print(\"üìö Gemini Reference Evaluation:\\n\", response.text)\n",
    "    score_match = re.search(r\"(\\d{1,2})/10\", response.text)\n",
    "    score = int(score_match.group(1)) if score_match else min(len(ref_list), rubric[\"bio_references\"])\n",
    "    return {\"valid_references\": len(ref_list), \"score\": score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score image resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_image_quality(image_data):\n",
    "    print(\"üîç Evaluating image resolution\")\n",
    "    high_res_count = sum(1 for img in image_data if img[\"is_high_res\"])\n",
    "    return {\"high_res_count\": high_res_count, \"score\": int((high_res_count / max(1, len(image_data))) * rubric[\"image_quality\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini: score image relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_image_relevance(image_data, architect_name, debug=False):\n",
    "    print(\"üîç Evaluating image relevance using Gemini\")\n",
    "    relevance_scores = []\n",
    "    for img in image_data:\n",
    "        prompt = f\"\"\"\n",
    "You are evaluating whether this image is relevant to a project on the architect {architect_name}.\n",
    "1. Does this image depict a building by {architect_name}? If yes, say which building if you can.\n",
    "2. Is this an interior or exterior shot?\n",
    "3. Is this a high-quality academic image that clearly shows architectural features (composition, lighting, layout)?\n",
    "Give a score out of 10 for academic relevance with a brief justification.\n",
    "\"\"\"\n",
    "        try:\n",
    "            response = vision_model.generate_content([img[\"image\"], prompt])\n",
    "            if debug:\n",
    "                print(f\"üì∑ Gemini Vision Feedback (Page {img['page']}):\", response.text)\n",
    "            match = re.search(r\"(\\d{1,2})/10\", response.text)\n",
    "            score = int(match.group(1)) if match else 5\n",
    "        except:\n",
    "            score = 5\n",
    "        relevance_scores.append(score)\n",
    "    avg_score = sum(relevance_scores) / max(1, len(relevance_scores))\n",
    "    return {\"avg_score\": avg_score, \"score\": int((avg_score / 10) * rubric[\"image_relevance\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini: score remaining rubric items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_full_rubric_eval(text, architect_name, debug=False):\n",
    "    print(\" Gemini evaluating extended rubric\")\n",
    "    prompt = (\n",
    "        f\"\"\"\n",
    "You are grading a student submission for a university architecture course. The project includes:\n",
    "\n",
    "- A biography of {architect_name}\n",
    "- 10 buildings they designed, with exterior and interior images\n",
    "- Proper image citations\n",
    "- 5‚Äì10 academic references\n",
    "- A personal student bio and image\n",
    "\n",
    "Follow this official rubric, scoring each from 1‚Äì5:\n",
    "\n",
    "1. **Architect Selection & Scope** ‚Äì Is the architect from Book Two? Is the scope appropriate?\n",
    "2. **Organization & Doc Setup** ‚Äì Table of contents? Clear sections? Logical structure?\n",
    "3. **Image Citation & Attribution** ‚Äì Are URLs provided? Are captions included under each image?\n",
    "4. **Coverage of 10 Buildings** ‚Äì Are there 10 buildings? With 5+ interior images per building?\n",
    "5. **Student Bio & Photo** ‚Äì Is the student‚Äôs 1-page bio included after the main content? Is the photo clear and professional? there is always an image included so should be a 5\n",
    "6. **Presentation Polish** ‚Äì Consistent formatting, readability, academic tone, clean layout\n",
    "\n",
    "For each category, give a score from 1 (poor) to 5 (excellent), and justify briefly.\n",
    "\"\"\"\n",
    "    )\n",
    "    response = text_model.generate_content([prompt, text])\n",
    "    print(response.text)\n",
    "    def extract_score(label):\n",
    "        match = re.search(label + r\".*?(\\d{1})\", response.text, re.IGNORECASE)\n",
    "        return int(match.group(1)) if match else 3\n",
    "\n",
    "    return {\n",
    "        \"architect_chosen\": {\"score\": extract_score(\"Architect Selection\")},\n",
    "        \"doc_and_slides\": {\"score\": extract_score(\"Organization\")},\n",
    "        \"image_citations\": {\"score\": extract_score(\"Image Citation\")},\n",
    "        \"10_buildings_with_images\": {\"score\": extract_score(\"Coverage\")},\n",
    "        \"personal_bio_photo\": {\"score\": extract_score(\"Personal Bio\")},\n",
    "        \"presentation_polish\": {\"score\": extract_score(\"Presentation\")},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using chain of thought "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_full_rubric_eval(text, architect_name, debug=False):\n",
    "    print(\" Gemini evaluating extended rubric\")\n",
    "    prompt = (\n",
    "        f\"\"\"\n",
    "You are grading a student submission for a university architecture course. The project includes:\n",
    "\n",
    "- A biography of {architect_name}\n",
    "- 10 buildings they designed, with exterior and interior images\n",
    "- Proper image citations\n",
    "- 5‚Äì10 academic references\n",
    "- A personal student bio and image\n",
    "\n",
    "Follow this official rubric. For **each category**, think step by step. First, describe your reasoning based on what you observed in the submission. Then, provide a score from 1 (poor) to 5 (excellent). Be generous but fair.\n",
    "\n",
    "Use the following format per category:\n",
    "\n",
    "**[Category Name]**\n",
    "Step-by-step reasoning: ...\n",
    "Score: x/5\n",
    "\n",
    "The categories are:\n",
    "\n",
    "1. **Architect Selection & Scope**  \n",
    "   - Is the architect from Book Two?  \n",
    "   - Is the project‚Äôs coverage of their work appropriate?\n",
    "\n",
    "2. **Organization & Doc Setup**  \n",
    "   - Does the document have a table of contents?  \n",
    "   - Are sections clearly separated and logically ordered?\n",
    "\n",
    "3. **Image Citation & Attribution**  \n",
    "   - Are all images properly captioned with source or photographer?  \n",
    "   - Are links or attributions provided clearly?\n",
    "\n",
    "4. **Coverage of 10 Famous Buildings**  \n",
    "   - Are 10 buildings discussed?  \n",
    "   - Are there multiple images (exterior + 5+ interior) per building?\n",
    "\n",
    "5. **Student Bio & Photo**  \n",
    "   - Is there a 1-page student bio included after the main content?  \n",
    "   - Is a photo present and reasonably professional?\n",
    "\n",
    "6. **Presentation & Polish**  \n",
    "   - Is formatting consistent?  \n",
    "   - Is the writing clear and academically appropriate?  \n",
    "   - Does the layout look well-organized?\n",
    "\n",
    "Please output your full evaluation using the structure above. Think carefully for each item before scoring. Be constructive in feedback.\n",
    "\"\"\"\n",
    "    )\n",
    "    response = text_model.generate_content([prompt, text])\n",
    "    print(response.text)\n",
    "    def extract_score(label):\n",
    "        match = re.search(label + r\".*?(\\d{1})\", response.text, re.IGNORECASE)\n",
    "        return int(match.group(1)) if match else 3\n",
    "\n",
    "    return {\n",
    "        \"architect_chosen\": {\"score\": extract_score(\"Architect Selection\")},\n",
    "        \"doc_and_slides\": {\"score\": extract_score(\"Organization\")},\n",
    "        \"image_citations\": {\"score\": extract_score(\"Image Citation\")},\n",
    "        \"10_buildings_with_images\": {\"score\": extract_score(\"Coverage\")},\n",
    "        \"personal_bio_photo\": {\"score\": extract_score(\"Personal Bio\")},\n",
    "        \"presentation_polish\": {\"score\": extract_score(\"Presentation\")},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scorecard(scores):\n",
    "    print(\" Generating scorecard\")\n",
    "    total = sum([v[\"score\"] for v in scores.values()])\n",
    "    return {\n",
    "        \"scorecard\": {k: v[\"score\"] for k, v in scores.items()},\n",
    "        \"final_score\": total,\n",
    "        \"grade\": \"A\" if total >= 90 else \"B\" if total >= 80 else \"C\" if total >= 70 else \"D\",\n",
    "        \"details\": scores\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_autograder(pdf_path, architect_name=\"Bjarke Ingels\"):\n",
    "    print(\" Starting pipeline\")\n",
    "    doc_text = extract_text_from_pdf(pdf_path)\n",
    "    images = extract_images_from_pdf(pdf_path)\n",
    "    references = extract_references_from_text(doc_text)\n",
    "\n",
    "    scores = {\n",
    "        \"bio_750_words\": {\"score\": evaluate_biography(doc_text)[\"score\"]},\n",
    "        \"bio_structure\": {\"score\": evaluate_biography(doc_text)[\"structure_score\"]},\n",
    "        \"bio_references\": evaluate_references(references),\n",
    "        \"image_quality\": evaluate_image_quality(images),\n",
    "        \"image_relevance\": evaluate_image_relevance(images, architect_name)\n",
    "    }\n",
    "    gemini_scores = gemini_full_rubric_eval(doc_text, architect_name)\n",
    "    scores.update(gemini_scores)\n",
    "    bio_feedback = gemini_bio_score(doc_text, architect_name)\n",
    "    print(\"\\n Gemini Feedback on Bio:\\n\", bio_feedback)\n",
    "    print(\" Evaluation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting pipeline\n",
      "üîç Extracting text from: /Users/tanishqsingh/Desktop/XR_Lab/cogs160submisson1.pdf\n",
      "‚úî Extracted text from PDF\n",
      " Extracting images from: /Users/tanishqsingh/Desktop/XR_Lab/cogs160submisson1.pdf\n",
      " Extracted 79 images from PDF\n",
      "üîç Extracting references from text\n",
      " Evaluating biography: checking word count and required sections\n",
      " Evaluating biography: checking word count and required sections\n",
      " Evaluating references\n",
      "üîç Evaluating image resolution\n",
      "üîç Evaluating image relevance using Gemini\n",
      " Gemini evaluating extended rubric\n",
      "Here's a grading of the student's submission based on the provided rubric:\n",
      "\n",
      "* **1. Architect Selection & Scope (5/5):** Bjarke Ingels is a relevant and appropriate choice for a contemporary architecture course. The scope of covering 10 buildings is acceptable, providing a reasonable overview of his work.\n",
      "\n",
      "* **2. Organization & Doc Setup (3/5):**  While a table of contents is present and the sections are generally clear, the document's structure could be improved. The student bio at the beginning is unusual; it should be placed at the end.  The biography section is also repeated, which is redundant.  Clearer labeling of sections (e.g., \"Building Analysis\" instead of just the number) would enhance readability.\n",
      "\n",
      "* **3. Image Citation & Attribution (2/5):** The URLs are provided, which is good. However, there are no proper captions beneath the images.  Captions should include title, date, location, and a brief description. Simply repeating the URL is not sufficient. This needs significant improvement.\n",
      "\n",
      "* **4. Coverage of 10 Buildings (4/5):**  The student has selected 10 buildings.  While the requirement states 5+ _interior_ images, this is difficult with projects like Superkilen or the Dryline, which are more landscape/urban design than buildings with traditional interiors.  The student acknowledges this, which is good.  However, for the buildings that *do* have interiors, the student sometimes falls short of 5 interior images.  More effort could have been made to find interior shots.\n",
      "\n",
      "* **5. Student Bio & Photo (5/5):**  The student bio is included (though misplaced at the beginning) and provides relevant information. There's an image, fulfilling the requirement for full marks.  The prompt indicates a 1-page bio, this one appears shorter but there's no penalty for brevity.\n",
      "\n",
      "* **6. Presentation Polish (3/5):**  The formatting is inconsistent. The repeated biography section is a major flaw. The use of bold text is not always consistent. The writing quality of the building descriptions and the biography is decent, but could be more analytical and less descriptive in some areas. The layout is generally clean, but more visual hierarchy (headings, subheadings, bullet points) would enhance readability.\n",
      "\n",
      "\n",
      "**Overall Comments:**\n",
      "\n",
      "The submission demonstrates a basic understanding of Bjarke Ingels' work. However, it needs further refinement in terms of image citation, document structure, and presentation.  The student should focus on providing proper image captions, reorganizing the document to flow more logically, and improving the consistency of formatting.  More in-depth analysis of the chosen buildings would strengthen the project. The repeated biography section needs to be addressed.  With these improvements, the project could achieve a much higher grade.\n",
      "\n",
      " Sending biography text to Gemini for evaluation of Bjarke Ingels\n",
      "\n",
      " Gemini Feedback on Bio:\n",
      " Score: 6/10\n",
      "\n",
      "This biography provides a decent overview of Bjarke Ingels and his architectural firm BIG, showcasing some of his key projects and highlighting his design philosophy. It successfully introduces Ingels' background, including his studies at the Royal Danish Academy of Fine Arts and Escola T√®cnica Superior d‚ÄôArquitectura in Barcelona, and his early career with Rem Koolhaas and PLOT Architects.  The biography also mentions the VM Houses as his first major project.  The student effectively explains Ingels' concepts of \"hedonistic sustainability\" and \"utopian pragmatism\" and illustrates them with relevant project examples. However, the biography lacks depth in analyzing the significance and influence of Ingels' buildings beyond superficial descriptions.  While various building types are mentioned, a more systematic categorization would be beneficial. Additionally, the excessive use of links disrupts the flow of the text and should be streamlined to a select few key resources placed at the end.  The inclusion of two biography sections and the \"My Bio\" section about the student are unnecessary and detract from the focus on Ingels.  Finally, while a range of projects are discussed, some notable early works that could provide deeper insight into his development as an architect are absent.\n",
      "\n",
      " Evaluation complete.\n",
      "null\n"
     ]
    }
   ],
   "source": [
    "result = run_autograder(pdf_path, \"Bjarke Ingels\")  \n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_setup_llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
